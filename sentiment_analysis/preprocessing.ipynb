{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca819ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col, udf, array_join\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyvi.ViTokenizer import ViTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cb429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init spark session\n",
    "spark = SparkSession.builder.master('local[*]').config('spark.ui.port', '4040').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30cdb776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+\n",
      "|              review|rating|place_index|\n",
      "+--------------------+------+-----------+\n",
      "|Gà ướp vừa vị , m...|     5|          0|\n",
      "|Quán sạch, đẹp, t...|     5|          0|\n",
      "|Nhân viên bự con ...|     5|          0|\n",
      "|Gà giòn tan, nóng...|     5|          0|\n",
      "|Gà giòn rụm, thấm...|     5|          0|\n",
      "|Nhân viên thân th...|     5|          0|\n",
      "|Phục vụ nhanh, nh...|     5|          0|\n",
      "|Gà rán thì ở đâu ...|     5|          0|\n",
      "|Nhân viên phục vụ...|     5|          0|\n",
      "|Mình là fan KFC, ...|     5|          0|\n",
      "|Gà giòn ngon dù đ...|     5|          0|\n",
      "|Mình có ghé đây ă...|     5|          0|\n",
      "|Ghé quán vào 1 bu...|     5|          0|\n",
      "|Nhân viên thân th...|     5|          0|\n",
      "|Ăn nhiều brand gà...|     5|          0|\n",
      "|Mới ghé tại nhà h...|     5|          0|\n",
      "|Đồ ăn nóng hổi, c...|     5|          0|\n",
      "|Ngon lắm mn ơi. Q...|     5|          0|\n",
      "|Ghé vào buổi tối,...|     5|          0|\n",
      "|Ghé ăn trưa cùng ...|     5|          0|\n",
      "+--------------------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_fp = \"hdfs://namenode:9000/review_data/reviews.csv\"\n",
    "df = spark.read.csv(review_fp, header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b8cfe",
   "metadata": {},
   "source": [
    "# Encoding Rating into sentiments\n",
    "Ratings above 3 stars are considered positive, below 3 stars are considered negative and neutral otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593fff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+---------+\n",
      "|              review|rating|place_index|sentiment|\n",
      "+--------------------+------+-----------+---------+\n",
      "|Gà ướp vừa vị , m...|     5|          0| positive|\n",
      "|Quán sạch, đẹp, t...|     5|          0| positive|\n",
      "|Nhân viên bự con ...|     5|          0| positive|\n",
      "|Gà giòn tan, nóng...|     5|          0| positive|\n",
      "|Gà giòn rụm, thấm...|     5|          0| positive|\n",
      "|Nhân viên thân th...|     5|          0| positive|\n",
      "|Phục vụ nhanh, nh...|     5|          0| positive|\n",
      "|Gà rán thì ở đâu ...|     5|          0| positive|\n",
      "|Nhân viên phục vụ...|     5|          0| positive|\n",
      "|Mình là fan KFC, ...|     5|          0| positive|\n",
      "|Gà giòn ngon dù đ...|     5|          0| positive|\n",
      "|Mình có ghé đây ă...|     5|          0| positive|\n",
      "|Ghé quán vào 1 bu...|     5|          0| positive|\n",
      "|Nhân viên thân th...|     5|          0| positive|\n",
      "|Ăn nhiều brand gà...|     5|          0| positive|\n",
      "|Mới ghé tại nhà h...|     5|          0| positive|\n",
      "|Đồ ăn nóng hổi, c...|     5|          0| positive|\n",
      "|Ngon lắm mn ơi. Q...|     5|          0| positive|\n",
      "|Ghé vào buổi tối,...|     5|          0| positive|\n",
      "|Ghé ăn trưa cùng ...|     5|          0| positive|\n",
      "+--------------------+------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_encoded = df.withColumn(\"sentiment\",\n",
    "    when(col(\"rating\") > 3, \"positive\")\n",
    "    .when(col(\"rating\") == 3, \"neutral\")\n",
    "    .otherwise(\"negative\")\n",
    ")\n",
    "df_encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b07ffd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+---------+\n",
      "|              review|rating|place_index|sentiment|\n",
      "+--------------------+------+-----------+---------+\n",
      "|Khi tôi đặt 5 cán...|     1|          0| negative|\n",
      "|Gọi gà nướng, bắt...|     1|          0| negative|\n",
      "|Thanh gà trong co...|     2|          0| negative|\n",
      "|Đặt hàng trên Sho...|     1|          0| negative|\n",
      "|Làm ăn cà chớn, đ...|     1|          0| negative|\n",
      "|Làm ăn tệ hại,bỏ ...|     1|          0| negative|\n",
      "|Thái độ nhân viên...|     1|          0| negative|\n",
      "|Nhân viên ăn nói ...|     1|          0| negative|\n",
      "|Đồ ăn ngon bác bả...|     2|          0| negative|\n",
      "|Lần thứ 3 mua hàn...|     1|          0| negative|\n",
      "|Đặt grab mua milo...|     1|          0| negative|\n",
      "|Thời gian chờ lâu...|     1|          0| negative|\n",
      "|29/11/2021 mình c...|     1|          0| negative|\n",
      "|Nóng nực, thái độ...|     2|          0| negative|\n",
      "|Khuyên các bạn mu...|     1|          0| negative|\n",
      "|Muốn ăn 1 miệng g...|     1|          0| negative|\n",
      "|nhân viên chậm, đ...|     1|          0| negative|\n",
      "|Mua hàng mang đi ...|     3|          0|  neutral|\n",
      "|            Được rồi|     3|          0|  neutral|\n",
      "|                 ĐẾN|     2|          0| negative|\n",
      "+--------------------+------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_encoded.filter(df_encoded['sentiment'] != 'positive').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1b9ef",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d56e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stopwords from .txt\n",
    "url = 'https://drive.google.com/uc?id=1ZyLTTnY0fiLmZo66pcl_6AhJ8TJyjXqt'\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(\"stopwords.txt\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "with open(\"stopwords.txt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stopwords_list = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bbb0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UDF to tokenize using PyVi\n",
    "def pyvi_tokenize(text):\n",
    "    try:\n",
    "        if text and isinstance(text, str):\n",
    "            text = re.sub(r'[^\\w\\s\\.]', ' ', text)\n",
    "            tokens = ViTokenizer.tokenize(text).split()\n",
    "            return [token for token in tokens if token.strip()]\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error tokenizing text: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UDF to clean and normalize tokens\n",
    "def normalize_tokens(tokens):\n",
    "    try:\n",
    "        if not tokens:\n",
    "            return []\n",
    "\n",
    "        normalized = []\n",
    "        for token in tokens:\n",
    "            token = token.replace('_', ' ')            \n",
    "            clean_token = re.sub(r'[^\\w\\s]', '', token.lower())\n",
    "            clean_token = clean_token.strip()\n",
    "            if clean_token:\n",
    "                sub_tokens = clean_token.split()\n",
    "                normalized.extend(sub_tokens)\n",
    "\n",
    "        return normalized\n",
    "    except Exception as e:\n",
    "        print(f\"Error normalizing tokens: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e5ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register UDFs\n",
    "tokenize_udf = udf(pyvi_tokenize, ArrayType(StringType()))\n",
    "normalize_udf = udf(normalize_tokens, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ed0e2",
   "metadata": {},
   "source": [
    "Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "df_with_tokens = df_encoded.withColumn(\"tokens\", tokenize_udf(col(\"review\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stopwords_remover = StopWordsRemover() \\\n",
    "    .setInputCol(\"tokens\") \\\n",
    "    .setOutputCol(\"filtered_tokens\") \\\n",
    "    .setStopWords(stopwords_list) \\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "df_no_stopwords = stopwords_remover.transform(df_with_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "df_normalized = df_no_stopwords.withColumn(\"normalized_tokens\", normalize_udf(col(\"filtered_tokens\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7763f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tokens into a text column\n",
    "df_join = df_normalized.withColumn(\"cleaned_reviews\", array_join(col(\"normalized_tokens\"), \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f31ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop intermediate columns\n",
    "df_final = df_join.drop(\"tokens\", \"filtered_tokens\", \"normalized_tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final result\n",
    "print(\"Processed results:\")\n",
    "df_final.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5df57cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
