{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from classifiers import MLPClassifierWithPhoBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5594711",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "phobert_tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base-v2')\n",
    "apply_tokenization = lambda minibatch: phobert_tokenizer(\n",
    "    minibatch, return_tensors = 'pt', padding=True,\n",
    "    truncation=True, max_length=256\n",
    ")\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    optimizer: nn.Module,\n",
    "    track_loss: bool = False,\n",
    "    use_gpu: bool = False\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Performs backpropogation on `model` using `optimizer`.\n",
    "\n",
    "    :param nn.Module model: The model on which to perform backpropogation.\n",
    "    :param nn.utils.data.DataLoader train_loader: A DataLoader dispatching batches\n",
    "        for each backpropogations.\n",
    "    :param nn.Module loss_fn: The loss function to based on which to compute gradients.\n",
    "    :param nn.Module optimizer: The optimization algorithm for gradient descent.\n",
    "    :param bool track_loss: Whether or not to return average loss.\n",
    "        This is `False` by default.\n",
    "\n",
    "    :return: A list of loss values per batch if `track_loss=True` else an empty list.\n",
    "    :rtype: list[float]\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        tokenized_X = apply_tokenization(X)\n",
    "        \n",
    "        X_input_ids = tokenized_X['input_ids']\n",
    "        X_att_mask = tokenized_X['attention_mask']\n",
    "\n",
    "        if use_gpu:\n",
    "            X_input_ids = X_input_ids.cuda()\n",
    "            X_att_mask = X_att_mask.cuda()\n",
    "            y = y.cuda()\n",
    "        pred_value = model(X_input_ids, X_att_mask)\n",
    "        loss = loss_fn(pred_value, y)\n",
    "\n",
    "        # Compute the gradient with loss.backward()\n",
    "        # Then backpropogate with optimizer.step()\n",
    "        # However, to avoid accumulation of previous backward passes\n",
    "        # we need to call optimizer.zero_grad() to zero out the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if track_loss: total_loss += loss\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_model(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    return_true_preds: bool,\n",
    "    use_gpu: bool = False\n",
    ") -> tuple[float, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Evaluate `model` based on `loss_fn` and return the average loss along with\n",
    "    true predictions and the total labels corresponding to each class.\n",
    "\n",
    "    :param nn.Module model: The model on which to perform evaluation.\n",
    "    :param nn.utils.data.DataLoader test_loader: A DataLoader containing test data.\n",
    "    :param nn.Module loss_fn: The loss function to based on which to compute metrics.\n",
    "    :param bool return_true_preds: Whether or not to store statistics on correctly\n",
    "        classified labels. This is only meaningful in the case the `model` is a classifier.\n",
    "\n",
    "    :return: The average loss (per batch). If `return_true_preds=True` then the number of\n",
    "        correctly classified labels and the total labels corresponding to each class are returned as\n",
    "        `torch.Tensor`. If not, zero tensors are returned instead.\n",
    "    :rtype: tuple[float, torch.Tensor, torch.Tensor]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    correct_labels = torch.tensor([0, 0, 0])\n",
    "    total_labels = torch.tensor([0, 0, 0])\n",
    "\n",
    "    for X, y in test_loader:\n",
    "        tokenized_X = apply_tokenization(X)\n",
    "\n",
    "        X_input_ids = tokenized_X['input_ids']\n",
    "        X_att_mask = tokenized_X['attention_mask']\n",
    "\n",
    "        if use_gpu:\n",
    "            X_input_ids = X_input_ids.cuda()\n",
    "            X_att_mask = X_att_mask.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        pred = model(X_input_ids, X_att_mask)\n",
    "        total_loss += loss_fn(pred, y)\n",
    "\n",
    "        if return_true_preds:\n",
    "            pred_labels = pred.argmax(dim=1)\n",
    "            correct_preds = pred_labels[pred_labels == y].bincount().cpu()\n",
    "            true_counts = y.bincount().cpu()\n",
    "\n",
    "            for i, count in enumerate(correct_preds):\n",
    "                correct_labels[i] += count\n",
    "            for i, count in enumerate(true_counts):\n",
    "                total_labels[i] += count\n",
    "\n",
    "    return total_loss / len(test_loader), correct_labels, total_labels\n",
    "\n",
    "def run_epochs(\n",
    "    epochs: int,\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    optimizer: nn.Module, *,\n",
    "    update_rate: int | None = None\n",
    "):\n",
    "    num_dig = int(math.log10(epochs)) + 1\n",
    "    if update_rate is None:\n",
    "        update_rate = 1 if epochs <= 20 else 10\n",
    "    losses = {'train': [], 'test': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if not epoch % update_rate:\n",
    "            print(f\"\\033[102;30;1mEpoch {epoch + 1:>{num_dig}}/{epochs}\\033[0m\", end=' || ')\n",
    "\n",
    "        training_loss = train_model(\n",
    "            model, train_loader,\n",
    "            loss_fn, optimizer, track_loss=True,\n",
    "            use_gpu=torch.cuda.is_available()\n",
    "        )\n",
    "        if not epoch % update_rate:\n",
    "            print(f\"\\033[94;1mTraining loss: {training_loss:<10.6f}\\033[0m\", end=' | ')\n",
    "\n",
    "        loss, true_labels, total_labels = test_model(\n",
    "            model, test_loader, loss_fn, True,\n",
    "            use_gpu=torch.cuda.is_available()\n",
    "        )\n",
    "\n",
    "        if not epoch % update_rate:\n",
    "            acc_by_class = (true_labels / total_labels) * 100\n",
    "            avg_acc = (true_labels.sum() / total_labels.sum()) * 100\n",
    "            print(f\"\"\"\\033[94;1mEval Loss: {loss:<10.6f}\\033[0m\n",
    "  \\033[1mAverage Accuracy: {avg_acc:.4f}%\\033[0m\n",
    "  \\033[32;10mPos: {acc_by_class[0]:<7.4f}%\\033[0m | Neu: {acc_by_class[1]:<7.4f}% | \\033[31;10mNeg: {acc_by_class[2]:<7.4f}%\\033[0m\n",
    "\"\"\")\n",
    "        losses['train'].append(training_loss)\n",
    "        losses['test'].append(loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f44a3b5",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635ec70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a51759eb2de0:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7eff89243350>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').config('spark.ui.port', '4040').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5cdd1a",
   "metadata": {},
   "source": [
    "## Buidling torch's Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24885502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    sentiment_as_index = {\n",
    "        'positive': 0,\n",
    "        'neutral': 1,\n",
    "        'negative': 2\n",
    "    }\n",
    "    def __init__(self, data_as_spark_df):\n",
    "        self.data_as_rdd = data_as_spark_df.rdd.zipWithIndex()\n",
    "        self.len = data_as_spark_df.count()\n",
    "    \n",
    "    def __len__(self): return self.len\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        if index < 0 or index > self.len - 1:\n",
    "            raise ValueError('index exceeded length of dataframe')\n",
    "        \n",
    "        nth_row = (self.data_as_rdd\n",
    "                   .filter(lambda data: data[1] == index)\n",
    "                   .take(1)[0][0]\n",
    "        )\n",
    "        review, sentiment = nth_row\n",
    "\n",
    "        return review, ReviewDataset.sentiment_as_index[sentiment]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3658a",
   "metadata": {},
   "source": [
    "## Load train and test set\n",
    "and other computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab2c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = spark.read.parquet(\n",
    "    'hdfs://namenode:9000/training_data/train_set'\n",
    ")\n",
    "test_set = spark.read.parquet(\n",
    "    'hdfs://namenode:9000/training_data/test_set'\n",
    ")\n",
    "\n",
    "# computing the class count for later computation\n",
    "class_counts = train_set.groupBy('sentiment').count().collect()\n",
    "\n",
    "train_set, test_set = ReviewDataset(train_set), ReviewDataset(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe9acf6",
   "metadata": {},
   "source": [
    "**Compute the class weights for loss function**\n",
    "\n",
    "Here the class weight $C_i$ for the $i$-th class is computed by:\n",
    "$$\n",
    "    C_i = \\frac{\\text{n\\_samples}}{\\text{class\\_counts}_i\\cdot\\text{n\\_classes}}\n",
    "$$\n",
    "where:\n",
    "- n_samples: is the number of sample within the dataset considered. This will be the train_set above.\n",
    "- $\\text{class\\_counts}_i$: the number of samples belonging to class $i$.\n",
    "- n_classes: the total classes present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ebffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_weights = {class_: len(train_set) / (count * len(class_counts)) for class_, count in class_counts}\n",
    "sentiment_weights = torch.tensor([sentiment_weights[class_] for class_ in train_set.sentiment_as_index], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ced0b0",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7cff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1.5e-5\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle=True)\n",
    "\n",
    "review_model = MLPClassifierWithPhoBERT([512, 512], nn.LeakyReLU(.02))\n",
    "if torch.cuda.is_available():\n",
    "    sentiment_weights = sentiment_weights.cuda()\n",
    "    review_model.cuda()\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss(weight=sentiment_weights)\n",
    "optimizer = torch.optim.Adam(review_model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "losses = run_epochs(\n",
    "    epochs, review_model,\n",
    "    train_loader, test_loader,\n",
    "    cross_entropy, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877f117",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62704a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\n",
    "    'model_param': review_model.state_dict(),\n",
    "    'optimizer_param': optimizer.state_dict(),\n",
    "    'losses': losses,\n",
    "    'lr': learning_rate,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "}\n",
    "\n",
    "torch.save(states, 'work/models/03_05_25-epoch25-model.tar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".bigdata_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
