{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a38b38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from classifiers import ReviewClassifierWithPhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "phobert_tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base-v2')\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    optimizer: nn.Module,\n",
    "    track_loss: bool = False,\n",
    "    use_gpu: bool = False\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Performs backpropogation on `model` using `optimizer`.\n",
    "\n",
    "    :param nn.Module model: The model on which to perform backpropogation.\n",
    "    :param nn.utils.data.DataLoader train_loader: A DataLoader dispatching batches\n",
    "        for each backpropogations.\n",
    "    :param nn.Module loss_fn: The loss function to based on which to compute gradients.\n",
    "    :param nn.Module optimizer: The optimization algorithm for gradient descent.\n",
    "    :param bool track_loss: Whether or not to return loss on each backpropogation.\n",
    "        This is `False` by default.\n",
    "    :return: A list of loss values per batch if `track_loss=True` else an empty list.\n",
    "    :rtype: list[float]\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_loader, start=1):\n",
    "        tokenized_X = phobert_tokenizer(X, return_tensors='pt',\n",
    "                                padding=True, truncation=True,\n",
    "                                max_length=256)\n",
    "        \n",
    "        X_input_ids = tokenized_X['input_ids']\n",
    "        X_att_mask = tokenized_X['attention_mask']\n",
    "\n",
    "        if use_gpu:\n",
    "            X_input_ids = X_input_ids.cuda()\n",
    "            X_att_mask = X_att_mask.cuda()\n",
    "            y = y.cuda()\n",
    "        pred_value = model(X_input_ids, X_att_mask)\n",
    "        loss = loss_fn(pred_value, y)\n",
    "\n",
    "        # Compute the gradient with loss.backward()\n",
    "        # Then backpropogate with optimizer.step()\n",
    "        # However, to avoid accumulation of previous backward passes\n",
    "        # we need to call optimizer.zero_grad() to zero out the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if track_loss: losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_model(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    compute_accuracy: bool,\n",
    "    use_gpu: bool = False\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate `model` based on `loss_fn` and return the average score(s).\n",
    "\n",
    "    :param nn.Module model: The model on which to perform evaluation.\n",
    "    :param nn.utils.data.DataLoader test_loader: A DataLoader containing test data.\n",
    "    :param nn.Module loss_fn: The loss function to based on which to compute metrics.\n",
    "    :param bool compute_accuracy: Whether or not to compute accuracy. This is only\n",
    "        meaningful in the case the `model` is a classifier.\n",
    "    :return: The average loss (per batch) and average accuracy (per sample). If\n",
    "        `compute_accuracy=False` then average accuracy returned is 0.\n",
    "    :rtype: tuple[float, float]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    for X, y in test_loader:\n",
    "        tokenized_X = phobert_tokenizer(X, return_tensors='pt',\n",
    "                                padding=True, truncation=True,\n",
    "                                max_length=256)\n",
    "        \n",
    "        X_input_ids = tokenized_X['input_ids']\n",
    "        X_att_mask = tokenized_X['attention_mask']\n",
    "\n",
    "        if use_gpu:\n",
    "            X_input_ids = X_input_ids.cuda()\n",
    "            X_att_mask = X_att_mask.cuda()\n",
    "            y= y.cuda()\n",
    "        pred = model(X_input_ids, X_att_mask)\n",
    "        total_loss += loss_fn(pred, y)\n",
    "        if compute_accuracy:\n",
    "            labels = (pred.argmax(dim=1) == y)\n",
    "            total_accuracy += labels.type(torch.int).sum().item()\n",
    "    return total_loss / len(test_loader), total_accuracy / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f44a3b5",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635ec70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').config('spark.ui.port', '4040').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31147f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      "\n",
      "Total reviews: 3425\n",
      "+--------------------+---------+\n",
      "|              review|sentiment|\n",
      "+--------------------+---------+\n",
      "|3 miếng gà 105k n...| negative|\n",
      "|Gà ướp vừa vị , m...| positive|\n",
      "|Thật tuyệt với gà...| positive|\n",
      "|Quán sạch , đẹp ,...| positive|\n",
      "|Nhân_viên bự con ...| positive|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_fp = 'hdfs://namenode:9000/review_data/preprocessed'\n",
    "preprocessed_df = spark.read.csv(preprocessed_fp, header=True, inferSchema=True)\n",
    "preprocessed_df = preprocessed_df.drop('rating', 'place_index')\n",
    "\n",
    "preprocessed_df.printSchema()\n",
    "print(f'Total reviews: {preprocessed_df.count()}')\n",
    "preprocessed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5cdd1a",
   "metadata": {},
   "source": [
    "## Buidling torch's Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24885502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    sentiment_as_index = {\n",
    "        'positive': 0,\n",
    "        'neutral': 1,\n",
    "        'negative': 2\n",
    "    }\n",
    "    def __init__(self, data_as_spark_df):\n",
    "        self.data_as_rdd = data_as_spark_df.rdd.zipWithIndex()\n",
    "        self.len = data_as_spark_df.count()\n",
    "    \n",
    "    def __len__(self): return self.len\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        if index < 0 or index > self.len - 1:\n",
    "            raise ValueError('index exceeded length of dataframe')\n",
    "        \n",
    "        nth_row = (self.data_as_rdd\n",
    "                   .filter(lambda data: data[1] == index)\n",
    "                   .take(1)[0][0]\n",
    "        )\n",
    "        review, sentiment = nth_row\n",
    "\n",
    "        return review, ReviewDataset.sentiment_as_index[sentiment]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".bigdata_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
